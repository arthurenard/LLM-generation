name: gpt2
pretrained_model_name_or_path: gpt2
model_type: causal_lm
revision: main

# Quantization settings
quantization:
  enabled: false
  bits: 8  # 8, 4
  group_size: 128  # For GPTQ quantization

# Model loading settings
model_loading:
  use_cache: true
  torch_dtype: auto  # auto, float16, bfloat16, float32
  device_map: auto  # auto, balanced, sequential, or specific mapping
  trust_remote_code: false
  
# Tokenizer settings
tokenizer:
  padding_side: right
  truncation_side: right
  use_fast: true
  add_bos_token: false  # Whether to add BOS token automatically 