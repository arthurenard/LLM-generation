defaults:
  - model: gpt2
  - generation: default
  - logging: wandb
  - post_processing: default
  - _self_

# Output settings
output:
  dir: ./outputs
  format: jsonl
  save_interval: 1000  # Save after every 1000 samples

# Runtime settings
runtime:
  seed: 42
  device: cuda  # cuda, cpu, or specific device like cuda:0
  num_workers: 4
  distributed: false  # Enable distributed inference

# Hydra settings
hydra:
  run:
    dir: ${output.dir}/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${output.dir}/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num} 